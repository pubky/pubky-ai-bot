# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# REQUIRED CONFIGURATION
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# REQUIRED: Bot's BIP39 mnemonic phrase (12-24 words)
# Generate one at: https://iancoleman.io/bip39/ (for testing only!)
# Or use: npx bip39-cli generate
# WARNING: For production: Use a securely generated mnemonic!
PUBKY_BOT_MNEMONIC="word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12"

# REQUIRED: Primary AI provider (options: groq, openai, anthropic, openrouter)
AI_PRIMARY_PROVIDER=groq

# REQUIRED: At least one API key matching your AI_PRIMARY_PROVIDER
# Groq (recommended for cost-free development): https://console.groq.com
GROQ_API_KEY=gsk_your_groq_key_here
# OpenAI: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your_openai_key_here
# Anthropic: https://console.anthropic.com
ANTHROPIC_API_KEY=sk-ant-your_anthropic_key_here
# OpenRouter: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-your_openrouter_key_here

# REQUIRED: AI model names (must be compatible with your provider)
# Groq models: llama-3.1-8b-instant, llama-3.1-70b-versatile, mixtral-8x7b-32768
# OpenAI models: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# Anthropic models: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
# OpenRouter models (use provider prefix):
#   - openai/gpt-4-turbo-preview, openai/gpt-3.5-turbo
#   - anthropic/claude-3-opus, anthropic/claude-3-sonnet, anthropic/claude-3-haiku
#   - meta-llama/llama-3.1-70b-instruct, meta-llama/llama-3.1-8b-instruct
#   - google/gemini-pro, google/gemini-pro-1.5
#   - mistralai/mistral-large, mistralai/mixtral-8x7b-instruct
AI_MODEL_SUMMARY=llama-3.1-8b-instant
AI_MODEL_FACTCHECK=llama-3.1-8b-instant
AI_MODEL_CLASSIFIER=llama-3.1-8b-instant

# REQUIRED: Database connection URLs
# When using Docker Compose, these are provided by the compose file
# When running locally, set these to your PostgreSQL and Redis instances
REDIS_URL=redis://localhost:6379/0
DATABASE_URL=postgres://user:pass@localhost:5432/pubkybot

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# OPTIONAL CONFIGURATION (with defaults)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# Node environment (default: development)
NODE_ENV=development

# Log level (default: info for production, debug for development)
# Options: error, warn, info, http, verbose, debug, silly
LOG_LEVEL=info

# Pubky network selection (default: testnet)
# Options: "testnet" or "mainnet"
PUBKY_NETWORK=testnet

# Pubky homeserver URL (default: testnet homeserver)
# Formats supported:
# - A pubky:// URL: pubky://ufibwbmed6jeq9k4p583go95wofakh9fwpp4k734trq79pd9u1uy
# - A direct pubkey: ufibwbmed6jeq9k4p583go95wofakh9fwpp4k734trq79pd9u1uy
# - An HTTPS URL: https://homeserver.example
PUBKY_HOMESERVER_URL=ufibwbmed6jeq9k4p583go95wofakh9fwpp4k734trq79pd9u1uy

# Nexus API URL for fetching mentions (default: https://testnet.pubky.org)
PUBKY_NEXUS_API_URL=https://testnet.pubky.org

# Nexus API authentication (optional, leave empty if not required)
PUBKY_AUTH_USERNAME=
PUBKY_AUTH_PASSWORD=

# AI fallback providers (optional, comma-separated list)
# Uncomment to enable automatic failover to backup providers
#AI_FALLBACK_PROVIDERS=openai,anthropic,openrouter

# AI token limits for responses (optional, with generous defaults)
# Increase these if your AI provider supports larger contexts
# Default: 1500 tokens for summary and factcheck, 500 for classifier
#AI_MAX_TOKENS_SUMMARY=1500
#AI_MAX_TOKENS_FACTCHECK=1500
#AI_MAX_TOKENS_CLASSIFIER=500

# AI classifier temperature (optional, default: 0.1)
# 0 = deterministic, 1 = creative, 0.1 = slightly varied (recommended)
#AI_CLASSIFIER_TEMPERATURE=0.1

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# THREAD PROCESSING LIMITS (optional, with defaults)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# Maximum depth of parent posts to fetch (default: 100)
# Increase for very deep conversation threads
#THREAD_MAX_DEPTH=100

# Maximum total number of posts to process (default: 1500)
# Increase for large multi-participant discussions
#THREAD_MAX_POSTS=1500

# Maximum tokens to send to AI for processing (default: 15000)
# Increase if your AI provider supports larger contexts
#THREAD_MAX_TOKENS_FOR_AI=15000

# Token count that triggers a warning (default: 10000)
# Lower this to get earlier warnings about large threads
#THREAD_TOKEN_WARNING_THRESHOLD=10000

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# OPTIONAL FEATURES
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# Brave Search API (optional, only needed for fact-checking feature)
# Get your API key from: https://brave.com/search/api/
BRAVE_API_KEY=

# Brave MCP Server Connection (default: http://localhost:8921/mcp)
# When using Docker: http://brave-mcp:8921/mcp
# When running locally: http://localhost:8921/mcp
BRAVE_MCP_BASE_URL=http://brave-mcp:8921/mcp

# Brave MCP Authentication Token (optional)
# Format: Bearer <token> or just the token itself
#BRAVE_MCP_TOKEN=Bearer your-token-here

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# DOCKER CONFIGURATION (optional, only needed if customizing defaults)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# Docker build target (default: development)
# Options: development, production
# BUILD_TARGET=development

# Server port mapping (default: 3000)
# SERVER_PORT=3000

# PostgreSQL configuration (defaults shown)
# POSTGRES_DB=pubkybot
# POSTGRES_USER=pubkybot
# POSTGRES_PASSWORD=password
# POSTGRES_PORT=5432

# Redis port mapping (default: 6379)
# REDIS_PORT=6379

# Redis Commander port (default: 8081, only used with --profile debug)
# REDIS_COMMANDER_PORT=8081

# Brave MCP Server port (default: 8921)
# BRAVE_MCP_PORT=8921
